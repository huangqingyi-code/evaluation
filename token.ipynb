{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"文件名称: 'table_path'\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"我已经收到您的数据文件，我需要查看文件内容以对数据集有一个初步的了解。首先我会读取数据到 `df_name` 变量中，并通过 `df_name.info` 查看 NaN 情况和数据类型。\\n\\n```python\\n# Load the data into a DataFrame\\ndf_name = read_df('table_path')\\n\\n# Get the basic information of the dataset\\ndf_name.info(memory_usage=False)\\n```\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Execution result:\\n```pycon\\n<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 896 entries, 0 to 895\\nData columns (total 6 columns):\\n #   Column       Non-Null Count  Dtype  \\n---  ------       --------------  -----  \\n 0   date         896 non-null    object \\n 1   datetime     896 non-null    object \\n 2   cash_type    896 non-null    object \\n 3   card         807 non-null    object \\n 4   money        896 non-null    float64\\n 5   coffee_name  896 non-null    object \\ndtypes: float64(1), object(5)\\n```\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"接下来我将用 `df_name.head(3)` 来查看数据集的前 3 行。\\n\\n```python\\n# Show the first 3 rows to understand the structure\\ndf_name.head(3)\\n```\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Execution result:\\n```pycon\\ndate                 datetime cash_type                 card  money    coffee_name\\n0  2024-03-01  2024-03-01 10:15:50.520      card  ANON-0000-0000-0001   38.7          Latte\\n1  2024-03-01  2024-03-01 12:19:22.539      card  ANON-0000-0000-0002   38.7  Hot Chocolate\\n2  2024-03-01  2024-03-01 12:20:18.089      card  ANON-0000-0000-0002   38.7  Hot Chocolate\\n```\",\n",
    "    },\n",
    "]\n",
    "message_prefix = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are 数海闻涛, an expert Python data analyst developed by ZJUICI (Institute of Computer Innovation of Zhejiang University). Your job is to help user analyze datasets by writing Python code. Each markdown codeblock you write will be executed in an IPython environment, and you will receive the execution output. You should provide results analysis based on the execution output.\\nFor politically sensitive questions, security and privacy issues, or other non-data analyze questions, you will refuse to answer.\\n\\nRemember:\\n- Comprehend the user's requirements carefully & to the letter.\\n- If additional information is needed, feel free to ask the user.\\n- Give a brief description for what you plan to do & write Python code.\\n- You can use `read_df(uri: str) -> pd.DataFrame` function to read different file formats into DataFrame.\\n- When creating charts, prefer using `seaborn`.\\n- If error occurred, try to fix it.\\n- Response in the same language as the user.\\n- Today is 2024-08-05\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"我已经了解了数据集的基本信息。请问我可以帮您做些什么？\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabelqa数据格式转换成slim格式\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "with open(\"/data4/evaluation/evalset/table_qa_execuate_test/test_datas_zuizong.json\")as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "slim_datas = []\n",
    "for data in datas:\n",
    "    # paths = [\"/data3/yss/tabular-data/usa_gov_medical/2022-2023_Kindergarten_Immunization_Rates_by_School.csv\"]\n",
    "    paths = data[\"table_paths\"]\n",
    "    messages_trans = []\n",
    "    messages_trans.append(message_prefix[0])\n",
    "    for i,path in enumerate(paths):\n",
    "        table_path = path.split(\"/\")[-1]\n",
    "        df_name = f\"df{i+1}\"\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        for j,mes in enumerate(messages):\n",
    "            role = mes[\"role\"]\n",
    "            content = mes[\"content\"]\n",
    "            if j==2:\n",
    "                buffer = StringIO()\n",
    "                df.info(memory_usage=False,buf=buffer)\n",
    "                df_info = buffer.getvalue()\n",
    "                # df_info = df.info(memory_usage=False)\n",
    "                content = f\"Execution result:\\n```pycon\\n{df_info}\\n```\"\n",
    "            elif j==4:\n",
    "                df_head = df.head(3)\n",
    "                content = f\"Execution result:\\n```pycon\\n{df_head}\\n```\"\n",
    "            else:\n",
    "                content = content.replace(\"table_path\",table_path).replace(\"df_name\",df_name)\n",
    "            messages_trans.append({\"role\":role,\"content\":content})\n",
    "    messages_trans.append(message_prefix[-1])\n",
    "    messages_trans.append({\"role\":\"user\",\"content\":data[\"query\"]})\n",
    "    data[\"message\"] = messages_trans\n",
    "    slim_datas.append(data)\n",
    "with open(\"/data4/evaluation/evalset/table_qa_execuate_test/test_datas_zuizong_slim.json\",\"w\")as f:\n",
    "    json.dump(slim_datas,f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算两个tableqa结果的差值\n",
    "import json\n",
    "path1 = \"/data4/evaluation/output/result_table_qa.json\"\n",
    "path2 = \"/data4/evaluation/output/result_table_qa_.json\"\n",
    "with open(path1)as f:\n",
    "    datas1 = json.load(f)\n",
    "with open(path2)as f:\n",
    "    datas2 = json.load(f)\n",
    "diff_datas = []\n",
    "for i,data1 in enumerate(datas1):\n",
    "    data2 = datas2[i]\n",
    "    if data1[\"flag\"]!=data2[\"flag\"]:\n",
    "        diff_datas.append(data1)\n",
    "with open(\"/data4/evaluation/output/result_table_qa_diff.json\",\"w\")as f:\n",
    "    json.dump(diff_datas,f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data4/sft_output/qwen2-base-0804/checkpoint-1800/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151645\n",
      "<|im_end|>\n",
      "[151645]\n",
      "[151643]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# t3 = tokenizer.encode(\"_hello\",add_special_tokens=True)\n",
    "# print(t3)\n",
    "# print(tokenizer.decode([96724]))\n",
    "# print(tokenizer.decode([14990]))\n",
    "# print(tokenizer.decode([14990]))\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.eos_token)\n",
    "print(tokenizer.encode('<|im_end|>'))\n",
    "print(tokenizer.encode(\"<|endoftext|>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
