{
  "load_para": {
    "torch_dtype": "float32"
  },
  "generate_para": {
    "do_sample": "False",
    "max_new_tokens": 1024
  }
}